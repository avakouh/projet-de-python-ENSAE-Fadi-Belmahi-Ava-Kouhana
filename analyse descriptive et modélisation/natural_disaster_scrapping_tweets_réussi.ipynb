{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WjZUdaSxdmt",
        "outputId": "58e0644b-c2df-4468-ec6b-13173a8db557"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: snscrape in /usr/local/lib/python3.8/dist-packages (0.4.3.20220106)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from snscrape) (3.8.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from snscrape) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from snscrape) (2.23.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from snscrape) (4.9.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from snscrape) (2022.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "#nous sommes obligés par souci d'efficacité de créer un autre notebook pour le scrapping twitter\n",
        "#sinon, toute modification du code nous oblige à relancer également le scrapping \n",
        "#or, le scrapping prend plus d'une heure à être executé\n",
        "!pip install snscrape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pou09Wubxr3r"
      },
      "outputs": [],
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "import progressbar\n",
        "from time import sleep\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "nd_dict = {'natural_disaster': ['natural disaster since:2015-01-01 until:2022-01-01', 50000]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBp3kpDsxvT5",
        "outputId": "f00fde19-c5ce-4f00-cbd1-95635a5691ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\r[                                                                        ] N/A%"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "natural_disaster %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-c0131f2bc4bd>:12: FutureWarning: username is deprecated, use user.username instead\n",
            "  tweets_list1.append([tweet.date, tweet.id, tweet.content, tweet.username]) #declare the attributes to be returned\n",
            "[========================================================================] 100%\n"
          ]
        }
      ],
      "source": [
        "today = datetime.today().strftime('%Y%m%d')[2:]+'_'\n",
        "for data, nd_ in enumerate(nd_dict):\n",
        "    print(nd_, '%')\n",
        "    tweets_list1 = []\n",
        "    bar = progressbar.ProgressBar(maxval=nd_dict[nd_][1]+2, widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
        "    bar.start()\n",
        "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'{nd_dict[nd_][0]}').get_items()): #declare a username\n",
        "        bar.update(i+1)\n",
        "        if i>nd_dict[nd_][1]: #number of tweets you want to scrape\n",
        "            break\n",
        "        #print(nd__, i, tweet)\n",
        "        tweets_list1.append([tweet.date, tweet.id, tweet.content, tweet.username]) #declare the attributes to be returned\n",
        "    tweets_df1 = pd.DataFrame(tweets_list1, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])\n",
        "\n",
        "    tweets_df1[['Datetime', 'Text']].to_csv(f'{nd_}.csv')\n",
        "    bar.finish()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}